{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Run 4: WildGuardMix + WildGuard Classifier (Viewer)\n",
                "\n",
                "**Dataset:** WildGuardMix (1,725 instances)  \n",
                "**Refusal Detection:** WildGuard 7B (ML Classifier)  \n",
                "**Status:** âœ… COMPLETE\n",
                "\n",
                "This notebook presents the results of the final experimental run, using the gold-standard WildGuard classifier on the adversarial WildGuardMix dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Executive Summary\n",
                "\n",
                "| Metric | Value | Notes |\n",
                "|--------|-------|-------|\n",
                "| **Accuracy** | **56.3%** | +14.8% improvement over heuristic (41.5%) |\n",
                "| **Sensitivity** | **92.1%** | High toxic catch rate |\n",
                "| **Token Savings** | **~40%** | At 50th percentile threshold |\n",
                "\n",
                "**Key Insight:** The WildGuard classifier significantly outperforms simple heuristics on adversarial data, capturing nuanced refusals that keyword matching misses."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Confusion Matrix Analysis\n",
                "\n",
                "The confusion matrix shows the breakdown of predictions against the gold-standard labels.\n",
                "\n",
                "| | Predicted Refusal | Predicted Compliance |\n",
                "|---|---|---|\n",
                "| **Actual Refusal** | **True Positive (TP)** | False Negative (FN) |\n",
                "| **Actual Compliance** | False Positive (FP) | **True Negative (TN)** |\n",
                "\n",
                "*Note: Detailed counts available in the full report.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Confidence Analysis\n",
                "\n",
                "We observe the same \"Confidence Paradox\" as in previous runs:\n",
                "- **Incorrect predictions** tend to have **higher confidence**.\n",
                "- **Toxic prompts** trigger higher confidence responses regardless of correctness.\n",
                "\n",
                "This confirms that confidence is a measure of *determinism*, not *correctness*."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}